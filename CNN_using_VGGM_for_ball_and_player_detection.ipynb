{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivans14/Deep_Learning_Proj/blob/main/CNN_using_VGGM_for_ball_and_player_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50e59f02",
      "metadata": {
        "id": "50e59f02"
      },
      "source": [
        "# Ball and players detection for SoccerNet\n",
        "### Using CNN and the pretained model VGGM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d98dbff6",
      "metadata": {
        "id": "d98dbff6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import LocalResponseNorm\n",
        "\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "IPN27JHX3Ra5",
      "metadata": {
        "id": "IPN27JHX3Ra5"
      },
      "outputs": [],
      "source": [
        "# Import dataset as: train, validation and test splits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "68c45f52",
      "metadata": {
        "id": "68c45f52"
      },
      "outputs": [],
      "source": [
        "# Check some info regarding the images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "48c01c0f",
      "metadata": {
        "id": "48c01c0f"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (779133239.py, line 12)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn [4], line 12\u001b[1;36m\u001b[0m\n\u001b[1;33m    nn.Conv2d(in_channels = , out_channels = ,\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# CNN model\n",
        "out_features = 2 # Ball and players\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self,out_classes):\n",
        "        super().__init__()\n",
        "        self.out_classes = out_classes\n",
        "        activation_fn = nn.ReLU(0.1)\n",
        "        linear_inputs = 2\n",
        "        # Defining a Sequential pipeline for the entire CNN\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = , out_channels = ,\n",
        "                     kernel_size = ),\n",
        "            activation_fn,\n",
        "            LocalResponseNorm(2),   # Check: https://towardsdatascience.com/difference-between-local-response-normalization-and-batch-normalization-272308c034ac\n",
        "            nn.MaxPool2d(kernel_size = ,\n",
        "                        stride =),\n",
        "            \n",
        "            nn.Conv2d(in_channels = ,\n",
        "                     out_channels = ,\n",
        "                     kernel_size = ),\n",
        "            nn.MaxPool2d(kernel_size = ,\n",
        "                        stride =),\n",
        "            \n",
        "            nn.Flatten(), # Flattens a contiguous range of dims into a tensor.\n",
        "            # FFNN\n",
        "            activation_fn,\n",
        "            nn.Linear(36*9*9,),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Linear(,self.out_classes),\n",
        "            nn.Dropout(0.25),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "      \n",
        "    def forward(self):\n",
        "\n",
        "      return self.net(nn.sotmax(x))\n",
        "\n",
        "NN = Model(out_classes)\n",
        "device = device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')  # use cuda if possible\n",
        "model.to(device)\n",
        "print(model)\n",
        "\n",
        "# Definition of optimizer and loss functions\n",
        "optimizer = optim.Adam(NN.parameters(),lr=0.008)\n",
        "loss_fn = nn.CrossEntropyLoss() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ismoSfa33bBb",
      "metadata": {
        "id": "ismoSfa33bBb"
      },
      "outputs": [],
      "source": [
        "# Define training function\n",
        "\n",
        "def accuracy(target, pred):\n",
        "    return metrics.accuracy_score(target.detach().cpu().numpy(), pred.detach().cpu().numpy())\n",
        "\n",
        "# Set number of epochs according to computational power, time and results.\n",
        "batch_size = 64\n",
        "num_epochs = 4\n",
        "validation_every_steps = 500\n",
        "\n",
        "step = 0\n",
        "NN.train()\n",
        "\n",
        "train_accuracies = []\n",
        "valid_accuracies = []\n",
        "running_loss = 0\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    train_accuracies_batches = []\n",
        "    train_loss_batches = []\n",
        "    \n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        \n",
        "        # Forward pass, compute gradients, perform one training step.\n",
        "        # Your code here!\n",
        "        output = NN(inputs) # Pass the inouts through the NN\n",
        "        loss = loss_fn(output,targets) # Compute and Save loss\n",
        "        optimizer.zero_grad() #Clean up gradients\n",
        "        loss.backward() # Compute gradients based on the loss from the current batch\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Increment step counter\n",
        "        step += 1\n",
        "        \n",
        "        # Compute accuracy.\n",
        "        predictions = output.max(1)[1]\n",
        "        train_accuracies_batches.append(accuracy(targets, predictions))\n",
        "        \n",
        "        if step % validation_every_steps == 0:\n",
        "            \n",
        "            validation_loss = 0\n",
        "            # Append average training accuracy to list.\n",
        "            train_accuracies.append(np.mean(train_accuracies_batches))\n",
        "            \n",
        "            train_accuracies_batches = []\n",
        "        \n",
        "            # Compute accuracies on validation set.\n",
        "            valid_accuracies_batches = []\n",
        "            with torch.no_grad():\n",
        "                NN.eval()\n",
        "                for inputs, targets in test_loader:\n",
        "                    inputs, targets = inputs.to(device), targets.to(device)\n",
        "                    output = NN(inputs)\n",
        "                    loss = loss_fn(output, targets)\n",
        "\n",
        "                    predictions = output.max(1)[1]\n",
        "\n",
        "                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).\n",
        "                    valid_accuracies_batches.append(accuracy(targets, predictions) * len(inputs))\n",
        "\n",
        "                NN.train()\n",
        "                \n",
        "            # Append average validation accuracy to list.\n",
        "            valid_accuracies.append(np.sum(valid_accuracies_batches) / len(test_set))\n",
        "     \n",
        "            print(f\"Step {step:<5}   training accuracy: {train_accuracies[-1]}\")\n",
        "            print(f\"             test accuracy: {valid_accuracies[-1]}\")\n",
        "\n",
        "# Save model (i.e. its weights)\n",
        "torch.save(NN.state_dict(), 'trained_models/CNN_weights.pth')\n",
        "print(\"Finished training.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
